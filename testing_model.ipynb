{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trafile 2020.10.1\n",
    "import tarfile\n",
    "\n",
    "#pandas 1.1.3\n",
    "import pandas as pd\n",
    "\n",
    "# requests 2.24.0\n",
    "import re\n",
    "\n",
    "# tensorflow 2.4\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#nltk 3.5\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#matplotlip 3.3.2\n",
    "import matplotlib.pyplot as plt\n",
    "# numpy 1.19.5\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "# keras 2.4.3\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#sklearn 0.23.2\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ THE CSV FILE\n",
    "movie_reviews = pd.read_csv(\"./IMDB Dataset.csv\")\n",
    "\n",
    "movie_reviews.isnull().values.any()\n",
    "\n",
    "movie_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample of the data\n",
    "movie_reviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preproccessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data \n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = movie_reviews['sentiment']\n",
    "\n",
    "# when review is positive make it =1 , when it is negative make it =0\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data train:70% validation:10% test: 20%\n",
    "X_train, y_train = X[:35000],  y[:35000]\n",
    "X_val,y_val= X[35000:40000], y[35000:40000] \n",
    "X_test , y_test =X[40000:50000], y[40000:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizing  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract tokens from the text the number of tokens is 5000\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text to a numeric sequence \n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87377 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print('Found %s unique tokens.' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max length of sequence\n",
    "maxlen = 256\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model= tf.keras.models.load_model('model-lstm-sentiment-movie.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 256, 200)          17475400  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256, 128)          168448    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 17,664,489\n",
      "Trainable params: 189,089\n",
      "Non-trainable params: 17,475,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score  of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 20s 61ms/step - loss: 0.1030 - acc: 0.8712\n"
     ]
    }
   ],
   "source": [
    "score = lstm_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  testing starts here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### as shown in the out put of this code, the sequences of sentences are printed witht the propability of prediction\n",
    "- if the propability is smaller than .5 that means it is near to negative\n",
    "- if the propability is larger than .5 that means it is near to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[  83  118  182    4  131    9 3744   18    1  967 2229    2  250    1\n",
      "   12 2347 1314    4   99    1  218    3   16    8   12  935  347    4\n",
      "  209  979  414    6   10  209 1332   55  400  298    3   20  253   16\n",
      "  948    9    9   28   46   58  210   51   13    8  109   10  484    2\n",
      "    1   97   67   14    1   84  172    1  465  769    7    1   59   63\n",
      "   52   45 2380   27   26   28   86   38   79   44  426    3   70  207\n",
      "    2  112   19   60    9   27   26  266 1040  136   75   19  116   21\n",
      "   10    1   84  174    4  685 3411  100    7    1   12  112   19   40\n",
      "   96  284   14    8 1157  206  634   56  210    4    1 2164    3    8\n",
      "  358 2347   12    2  785 2052 1646   26   23    4  131 1535    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.02014571]\n",
      "negative review\n",
      "X=[ 124   10 2264    4   60 2900    9   56 2188 3875 1336   15  250    8\n",
      "  113    4   25   19  151   27   26    1 1151    2  176   20  234  661\n",
      "    4   71  190   70    2   45 4836  140   80   11  226   11   28   20\n",
      " 2056    6  376 3446   39   10 1559   14   44    2   23   52  434   13\n",
      "    6   80 1976 1796   14  281   28   20  621  292   15   35   61  289\n",
      "  228  151   39  130 2416   97    1 1384    3    1 1716 1254   31  153\n",
      "  374   22  534    1  534   31   29    1   91    5  373  524    2    1\n",
      "  184  665 1336  120  255    4  477   22   11 3814 2248   11   21   46\n",
      "   21  127  180   45  278   58   60   85  376  123    6    5   49 2043\n",
      "    2    1  745  153 2745    9   65   35   10   32   69 1011   14  136\n",
      "   34    8   15 1043   98    6 1195    2   82   61  459    4   99  160\n",
      "  406  112  187  356  145   77 2354  524  170   50  205 1802    2 1252\n",
      "   27  262   50  121   93   70   38  534    7    1  113  153   23    1\n",
      "  166  109 3660    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.02183545]\n",
      "negative review\n",
      "X=[  48   17  162   27    1  972    2  332  513   39    6   30 1064  276\n",
      "  527    3   12  263    4  320   68   43   17   71  126   87  170  266\n",
      "  332    1 2542   14    1   74   12  431  298   11   35   67  102   94\n",
      "    3    8  413  602   39    1  166   53   13  190 1985 1614    9   63\n",
      " 1324  798    7 1091  187  873  513   39    9   12  126  116  208    8\n",
      "   24    2   19    9   24    2    9   12    5   54  338   43   24   56\n",
      "  804   12   13    9  413   56   25   39   76   25 1118  523   47    3\n",
      "  994  527  418    2   17   71    9    7    8   12    4   44 2443  187\n",
      "   35    5   47  513 1154    1    2  662 1826   11    1  601  128    3\n",
      "    1   72  105  598  235   29    1   27    1  444    3    1   16   76\n",
      "    4    1   12   78   42    1  156  749    3  346  165 1179   28   75\n",
      "   19 4136    4   23   44  915  986    7    8  412    6    5    7  191\n",
      "    1   74   12   75   19   98   61   42    9 1324  756  384    9  217\n",
      "    7    1   12    2   60    1  572   14    8   24    5 1928   93  129\n",
      "    6   10   37   19    1   12   10  985    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.0235385]\n",
      "negative review\n",
      "X=[  14    1  280  100  126  134    1 1258  229   25 2554    1   58   91\n",
      "    4   33    6   14    1  438  379 1325    4   25 1957    6    5    4\n",
      "   71   11  103 1259 2281  328 3342   72   79   30 2719 2387   40    2\n",
      " 2325 3650    5    1 3234 1569   13 1764   31   10 2564   14    1  247\n",
      "    2   31   42 1617    8   15   43    1  280 3554    3 4350   21 1584\n",
      "   80 2325   42  836   31    5    4   25 1957   36    4   25 4125  132\n",
      "    6  675 1884    4 4350    9 2325  100   42  216  262    4 3037   72\n",
      "    3    1 2425   15    9   21   10 1428   27    1 3650  100   10    1\n",
      "  396   13    1 3618    7    1    2  142 4350    5   85   14 3364    2\n",
      "    2   41    9  213  193   21  483    4  531 1250   33    8   80    6\n",
      "  213 1224    2   21 1791   14    1  319    3    1   24  207   31    5\n",
      " 1851  422   55  491   81  355   46   17   71   43   78    9  819 1973\n",
      "   24    4  888 3408  695  416   39    8  403    3  591  378  102 1366\n",
      "    7  318   43   92   23   73  216   13    9   98 2748 1766    2   74\n",
      "   94   31   23   73   86   14  457 2239    2   67  129  123 1538  525\n",
      " 1869    9  154  953   24    4   60    8  591    2    4  842  141    1\n",
      "  125    3    8 2113  591    5   24    1   84 3421  177  135  216    8\n",
      "  282    6   52  575    9    1  948    3    8 2643    3   63 2839   11\n",
      "  353    2  413  157], Predicted=[0.01691988]\n",
      "negative review\n",
      "X=[   8   12   10   18 3142    1   74  245    2  154  356    6   27   26\n",
      "    1   83  723    3    1 2316   10   45  202   15    1  763  331  358\n",
      "    1  168  278    2  524    4  277    1  465  582 1148   45   27   26\n",
      "   28  139    3   63    1  209  278    2  209  524 2466   38  389   32\n",
      "    8   12  212    1   40    3  695  651   19   16    9   17   46  842\n",
      "  174    2   99    2  356    8    5   16    9   17  461    4  160 1168\n",
      "   36  181    6  140    4    1 1922   41 2525   36 1173    6   10   45\n",
      "    4   60 4865    1 4865  140   15  289   11  241   11    1   83   28\n",
      "  139    3   63    1  168  723   11  472 2049   51    2  129   63    2\n",
      " 4658   38  383    7    1   16    9   56  135   73  219  123   87    6\n",
      "   10    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.02112675]\n",
      "negative review\n",
      "X=[  10   45  795   23   19  332    1  261  455  105   30 4844  327    1\n",
      " 1292  213  201   88  683   35   67  214   48    1 1177    2   35   67\n",
      " 1010    4   71    6  198   10  115 3953    2    1  698  952   51    4\n",
      "    1  453 4302   67  244 3210   78  188   35   67   44  540  381   32\n",
      "   44    3    1  795  441  187  435   81   10  731    6   63   49  721\n",
      " 1042  395    4    1  502 3912 1542    2    6   61  264    1  854   43\n",
      "   13    1  445  353  159    2  445 1465    1 4227  381   67  652  964\n",
      "    8   10 1612   29   24    3    1   84 2392  204 4509    7 1292  266\n",
      "   19   11 1152   11    1   24    7   24  102   55   57  493   64 3998\n",
      "    1  107    5 1282   13   26    1 3113 4080  150   19   11 4469   11\n",
      "   55    2    7   44   91    9    5   45  146    1  109   10   49   45\n",
      "  597    5  116   46  351    8  643 1392   15   46   98    3  123  643\n",
      "    4 1643   22  237    7    1  203   11    2 1588    2   75 1351    4\n",
      "   62   97 2203    2    1 1423   63   77 3326    2   65 1399   18    1\n",
      "  218  559 1847   11 4413   26    7   26 1199  795   15  153 3825  335\n",
      "    1  114 4441    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.96169996]\n",
      "positive review\n",
      "X=[  24  915 1432    5    1 1575   19 2561    1  114   12   23  119  104\n",
      "   37   48   24  915  128    5  216  160    6  106 1522   17  363   37\n",
      "   24  146   95  160    1  718    5   77    1  693   20    1  198  638\n",
      "   14    1  133    6    5   78 2133   12  115    9    5 1656    7    6\n",
      "    3  259    6   42    1   59    3    1  423   17  578 1693   13  122\n",
      "  284  630   51 2939    2 1772  117   72   13   47 4963   31  182    4\n",
      "   60    6   41   28 1195   35    5  579  480    7    9  732    2  398\n",
      "   75   19  420   51    4  248  391 1480   24  139  205   23   30  813\n",
      "  320    2   26    1    8  190    4  732    2  398    7   24  915 1432\n",
      "    1  732   20  342    8    5   19  205    1  412    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.6610133]\n",
      "positive review\n",
      "X=[ 347  318 2340 1847 4074  168  347   54   14   85   13    1  569  569\n",
      "  506   16    9   26    3   22 1836  923 3979  449  330 1465    2  569\n",
      "    8   56   25   54  219 1294   41    1   16   27  223   63   30  211\n",
      "  107  539 4432    7   26   88  644 3126    5  478  458   15  506    5\n",
      "  914  331 1817 1842 1243    5   29 4098 2504    4  163   40   31   73\n",
      "   40    3 2910   17  225  531 2844   31    1    5  192  157  130  102\n",
      "   20   51    1  412   11  157    1 1269  213    1  107   15    1 1482\n",
      " 4465    3  574  238  105   13 1601    2    1 2742    3   87 2300   15\n",
      "    8   37  213  193    4    1  815  704    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.01977414]\n",
      "negative review\n",
      "X=[   8   10  408    1   84 1573 2643    3  427    4   57   23  119 1389\n",
      " 2249   19   58   10    1  389  596  230    1   16   42  364    4  161\n",
      "    4   75   13   15    1  109    5   11 4067    2   11    1  594    4\n",
      "  158   89   44  236    3  107   48   17   99    8   16   17  561  345\n",
      "   15 1081  169  329   48   17  135   63  193    2    6   53    4  461\n",
      "    6  118  476 4625  366    1  125    7   55  412    9  102  600    3\n",
      "   55  110    9   76  106   25  463    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.02600262]\n",
      "negative review\n",
      "X=[ 124   23  106 2612    1 1269    3    8  113    1  109    5  330  105\n",
      " 2853 1479    1 1614    3   84  689   20 3482    2    1  407    5  835\n",
      "    1  607 1986    2    6    5 1357    4  357    2  842  141   54  294\n",
      "   30  406 3894    1 4325  195    8  113    2    1    5  553  664    1\n",
      "  395    3 2594    2    1 1280    2  958  326   14    1  113    6  183\n",
      "    4   25  161   47   68  665 2900   13    1  166  156 1986  678 3115\n",
      "    9  665   23 1852   51   11  113   33 1674  155  589    7    1  436\n",
      "    9    6   76 3302   44 4597  787   36  136   34    9  190  661  464\n",
      "    2    1  575  155    1  166 2905   69   47 2502    2   20  158 1666\n",
      "    4   99    7 2054    4    8  484 1123 1343   14  113    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], Predicted=[0.02011287]\n",
      "negative review\n"
     ]
    }
   ],
   "source": [
    "### make class predictions with the model\n",
    "y_pred = lstm_model.predict(X_test)\n",
    "# summarize the first 10 cases\n",
    "for i in range(10):\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[i], y_pred[i]))\n",
    "    if y_pred[i] < 0.5:\n",
    "        print('negative review')\n",
    "    else:\n",
    "        print('positive review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matrix of values is the sentence when predicted is the  propability of positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can test it yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your value: i liked the movie so much. i will watch it again. i will invite my friends to watch it.\n"
     ]
    }
   ],
   "source": [
    "#you must run all the previuos cells\n",
    "TEST_REVIEW = input(\"Enter your value: \")\n",
    "#press enter to save the text into the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text(TEST_REVIEW)\n",
    "remove_tags(TEST_REVIEW)\n",
    "TEST_REVIEW = tokenizer.texts_to_sequences(TEST_REVIEW)\n",
    "TEST_REVIEW = pad_sequences(TEST_REVIEW, padding='post', maxlen=maxlen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=[0.69894475],  positive review \n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_model.predict(TEST_REVIEW)\n",
    "if y_pred[0] < 0.5:\n",
    "    value ='negative review'\n",
    "else:\n",
    "    value = 'positive review'\n",
    "print(\"Predicted=%s,  %s \" % ( y_pred[0], value ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### or only by a given example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive review\n",
    "TEST_REVIEW_positive = \"I was \\ on the edge of my seat the entire time. The acting was excellent, and the \\scenery - my goodness. Watch this movie now!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=[0.69894475],  positive review \n"
     ]
    }
   ],
   "source": [
    "preprocess_text(TEST_REVIEW_positive)\n",
    "remove_tags(TEST_REVIEW_positive)\n",
    "TEST_REVIEW = tokenizer.texts_to_sequences(TEST_REVIEW_positive)\n",
    "TEST_REVIEW = pad_sequences(TEST_REVIEW, padding='post', maxlen=maxlen)\n",
    "\n",
    "y_pred = lstm_model.predict(TEST_REVIEW)\n",
    "if y_pred[0] < 0.5:\n",
    "    value ='negative review'\n",
    "else:\n",
    "    value = 'positive review'\n",
    "print(\"Predicted=%s,  %s \" % ( y_pred[0], value ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative review\n",
    "TEST_REVIEW_negative = \"the acting was bad and not profisional I could'nt complete the movie and I slept in the middle of it I wont let my friends watch it because they will hate me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=[0.19478163],  negative review \n"
     ]
    }
   ],
   "source": [
    "preprocess_text(TEST_REVIEW_negative)\n",
    "remove_tags(TEST_REVIEW_negative)\n",
    "TEST_REVIEW = tokenizer.texts_to_sequences(TEST_REVIEW_negative)\n",
    "TEST_REVIEW = pad_sequences(TEST_REVIEW, padding='post', maxlen=maxlen)\n",
    "\n",
    "y_pred = lstm_model.predict(TEST_REVIEW)\n",
    "if y_pred[0] < 0.5:\n",
    "    value ='negative review'\n",
    "else:\n",
    "    value = 'positive review'\n",
    "print(\"Predicted=%s,  %s \" % ( y_pred[0], value ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nour Ammar y2013 140008\n",
      "Deep learning 2021 prof.Haluk Gumuskaya\n"
     ]
    }
   ],
   "source": [
    "print(\"Nour Ammar y2013 140008\")\n",
    "print(\"Deep learning 2021 prof.Haluk Gumuskaya\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
